{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8d36581-d342-42a6-82c1-8f19814b9367",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (78.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (1.73.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8adba88-f3b1-4d61-885f-08390f040464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03bc10dc-7898-4d3a-9c10-659df7273ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "NumPy version: 2.1.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"NumPy version:\", np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2233f7aa-89d3-4cc1-8b79-20cc87b30528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c2938b-0ee3-4ecf-be16-95ac2820d23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now in: C:\\Users\\ramesh\\anaconda3\\envs\\facenet_env\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r\"C:\\Users\\ramesh\\anaconda3\\envs\\facenet_env\")\n",
    "print(\"Now in:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de419cce-3d73-4f61-bc21-bdaaed00bd87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16bb1bb1-06d8-4ec5-a28e-4ee6a283c055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcf01e14-7275-459c-898d-985f6b9ef47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path exists: True\n",
      "Subfolders (classes): ['Akshay Kumar_1.jpg', 'Akshay Kumar_2.jpg', 'Akshay Kumar_3.jpg', 'Alia Bhatt_1.jpg', 'Alia Bhatt_2.jpg', 'Alia Bhatt_3.jpg', 'Amitabh Bachchan_1.jpg', 'Amitabh Bachchan_2.jpg', 'Amitabh Bachchan_3.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_path = r\"C:\\Users\\ramesh\\anaconda3\\envs\\facenet_env\\dataset\\train\"\n",
    "\n",
    "print(\"Path exists:\", os.path.exists(data_path))\n",
    "print(\"Subfolders (classes):\", os.listdir(data_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d44728f-51f4-4ca1-b977-486f687bf1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "src_dir = r\"C:\\Users\\ramesh\\anaconda3\\envs\\facenet_env\\dataset\\train\"\n",
    "for file in os.listdir(src_dir):\n",
    "    if file.endswith((\".jpg\", \".png\")):\n",
    "        name = \"_\".join(file.split(\"_\")[:-1])  # e.g., Akshay Kumar\n",
    "        folder = os.path.join(src_dir, name)\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        shutil.move(os.path.join(src_dir, file), os.path.join(folder, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6a22171-f53c-4dd0-9e39-ae1d617d9297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subfolders: ['Akshay Kumar', 'Alia Bhatt', 'Amitabh Bachchan']\n",
      "Akshay Kumar: 3 images\n",
      "Alia Bhatt: 3 images\n",
      "Amitabh Bachchan: 3 images\n"
     ]
    }
   ],
   "source": [
    "print(\"Subfolders:\", os.listdir(src_dir))\n",
    "for folder in os.listdir(src_dir):\n",
    "    path = os.path.join(src_dir, folder)\n",
    "    print(f\"{folder}: {len(os.listdir(path))} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ecb5b8b-a61a-42ad-8c3f-4a77251f3ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded triplets: 6\n",
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - loss: 0.4960\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 0.4737\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 0.4672   \n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.3272\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 757ms/step - loss: 0.0778\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 766ms/step - loss: 0.0345\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 610ms/step - loss: 0.0056\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 846ms/step - loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 838ms/step - loss: 0.0125\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a659486800>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# ========== SETTINGS ==========\n",
    "IMAGE_SIZE = (160, 160)\n",
    "DATASET_PATH = r\"C:\\Users\\ramesh\\anaconda3\\envs\\facenet_env\\dataset\\train\"\n",
    "MARGIN = 0.5  # For triplet loss\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "# ========== LOAD IMAGES ==========\n",
    "def load_images_from_folder(base_path):\n",
    "    data = {}\n",
    "    for person in os.listdir(base_path):\n",
    "        person_path = os.path.join(base_path, person)\n",
    "        if os.path.isdir(person_path):\n",
    "            images = []\n",
    "            for img_name in os.listdir(person_path):\n",
    "                img_path = os.path.join(person_path, img_name)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    img = cv2.resize(img, IMAGE_SIZE)\n",
    "                    img = img.astype(\"float32\") / 255.0\n",
    "                    images.append(img)\n",
    "            if len(images) >= 2:  # Need at least 2 per person\n",
    "                data[person] = images\n",
    "    return data\n",
    "\n",
    "# ========== MAKE TRIPLETS ==========\n",
    "def create_triplets(data_dict):\n",
    "    anchors, positives, negatives = [], [], []\n",
    "    people = list(data_dict.keys())\n",
    "    \n",
    "    for person in people:\n",
    "        pos_images = data_dict[person]\n",
    "        for i in range(len(pos_images) - 1):\n",
    "            anchor = pos_images[i]\n",
    "            positive = pos_images[i + 1]\n",
    "            \n",
    "            # Pick a negative from another class\n",
    "            neg_person = np.random.choice([p for p in people if p != person])\n",
    "            import random  # Add at the top if not already\n",
    "            negative = random.choice(data_dict[neg_person])\n",
    "            \n",
    "            anchors.append(anchor)\n",
    "            positives.append(positive)\n",
    "            negatives.append(negative)\n",
    "    \n",
    "    print(f\"Loaded triplets: {len(anchors)}\")\n",
    "    return np.array(anchors), np.array(positives), np.array(negatives)\n",
    "\n",
    "# ========== EMBEDDING MODEL ==========\n",
    "def build_embedding_model():\n",
    "    inp = Input(shape=(160, 160, 3))\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(inp)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    out = layers.Lambda(lambda y: tf.math.l2_normalize(y, axis=1))(x)\n",
    "    return models.Model(inputs=inp, outputs=out)\n",
    "\n",
    "# ========== TRIPLET LOSS ==========\n",
    "def triplet_loss(y_true, y_pred):\n",
    "    anchor, positive, negative = y_pred[:,0,:], y_pred[:,1,:], y_pred[:,2,:]\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=1)\n",
    "    basic_loss = pos_dist - neg_dist + MARGIN\n",
    "    return tf.reduce_mean(tf.maximum(basic_loss, 0.0))\n",
    "\n",
    "# ========== TRAINING MODEL ==========\n",
    "import tensorflow as tf  # Add this if not already\n",
    "\n",
    "def build_training_model(embedding_model):\n",
    "    anchor_inp = layers.Input(name=\"anchor\", shape=(160, 160, 3))\n",
    "    pos_inp = layers.Input(name=\"positive\", shape=(160, 160, 3))\n",
    "    neg_inp = layers.Input(name=\"negative\", shape=(160, 160, 3))\n",
    "\n",
    "    anchor_embed = embedding_model(anchor_inp)\n",
    "    pos_embed = embedding_model(pos_inp)\n",
    "    neg_embed = embedding_model(neg_inp)\n",
    "\n",
    "    # Replace K.expand_dims with tf.expand_dims\n",
    "    anchor_embed = layers.Lambda(\n",
    "        lambda x: tf.expand_dims(x, axis=1),\n",
    "        output_shape=lambda s: (s[0], 1, s[1])\n",
    "    )(anchor_embed)\n",
    "\n",
    "    pos_embed = layers.Lambda(\n",
    "        lambda x: tf.expand_dims(x, axis=1),\n",
    "        output_shape=lambda s: (s[0], 1, s[1])\n",
    "    )(pos_embed)\n",
    "\n",
    "    neg_embed = layers.Lambda(\n",
    "        lambda x: tf.expand_dims(x, axis=1),\n",
    "        output_shape=lambda s: (s[0], 1, s[1])\n",
    "    )(neg_embed)\n",
    "\n",
    "    merged = layers.Concatenate(axis=1)([anchor_embed, pos_embed, neg_embed])\n",
    "\n",
    "    model = models.Model(inputs=[anchor_inp, pos_inp, neg_inp], outputs=merged)\n",
    "    model.compile(loss=triplet_loss, optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "# ========== RUN PIPELINE ==========\n",
    "data = load_images_from_folder(DATASET_PATH)\n",
    "anchors, positives, negatives = create_triplets(data)\n",
    "\n",
    "# shuffle\n",
    "anchors, positives, negatives = shuffle(anchors, positives, negatives, random_state=42)\n",
    "\n",
    "embedding_model = build_embedding_model()\n",
    "training_model = build_training_model(embedding_model)\n",
    "\n",
    "y_dummy = np.zeros((anchors.shape[0], 1))  # Not used, required by Keras\n",
    "\n",
    "training_model.fit(\n",
    "    [anchors, positives, negatives],\n",
    "    y_dummy,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d734c0da-4f7b-4ee5-b548-8ebdf42e4982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "Predicted identity: Akshay Kumar (similarity: 0.9589)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = 160\n",
    "TRAIN_DIR = 'dataset/train'\n",
    "TEST_DIR = 'dataset/test'\n",
    "\n",
    "# Preprocessing Function\n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "    img = img_to_array(img)\n",
    "    img = img / 255.0  # Normalize\n",
    "    return np.expand_dims(img, axis=0)\n",
    "\n",
    "# 1. Get embeddings of training images\n",
    "def get_train_embeddings(embedding_model, train_dir):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "\n",
    "    for person_name in os.listdir(train_dir):\n",
    "        person_folder = os.path.join(train_dir, person_name)\n",
    "        if not os.path.isdir(person_folder):\n",
    "            continue\n",
    "        for img_name in os.listdir(person_folder):\n",
    "            img_path = os.path.join(person_folder, img_name)\n",
    "            img = preprocess_image(img_path)\n",
    "            emb = embedding_model.predict(img)\n",
    "            embeddings.append(emb[0])\n",
    "            labels.append(person_name)\n",
    "    return np.array(embeddings), labels\n",
    "\n",
    "# 2. Get embedding of test image\n",
    "def get_test_embedding(embedding_model, test_image_path):\n",
    "    img = preprocess_image(test_image_path)\n",
    "    emb = embedding_model.predict(img)\n",
    "    return emb[0]\n",
    "\n",
    "# 3. Predict\n",
    "def predict_identity(test_embedding, train_embeddings, train_labels):\n",
    "    similarities = cosine_similarity([test_embedding], train_embeddings)\n",
    "    best_match_idx = np.argmax(similarities)\n",
    "    return train_labels[best_match_idx], similarities[0][best_match_idx]\n",
    "\n",
    "# ======= Run Testing =======\n",
    "test_image_path = os.path.join(TEST_DIR, 'test.jpg')\n",
    "\n",
    "# Step 1: Get embeddings from training data\n",
    "train_embeddings, train_labels = get_train_embeddings(embedding_model, TRAIN_DIR)\n",
    "\n",
    "# Step 2: Embed test image\n",
    "test_embedding = get_test_embedding(embedding_model, test_image_path)\n",
    "\n",
    "# Step 3: Predict\n",
    "identity, score = predict_identity(test_embedding, train_embeddings, train_labels)\n",
    "\n",
    "print(f\"Predicted identity: {identity} (similarity: {score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a537ea5-4ead-4dae-9bf1-7f52b1cebb0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05a4c053-8f9b-4be7-80f4-8c1ddb9486d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping keras-facenet as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-facenet\n",
      "  Downloading keras-facenet-0.3.2.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting mtcnn (from keras-facenet)\n",
      "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: joblib>=1.4.2 in c:\\users\\ramesh\\anaconda3\\envs\\facenet_env\\lib\\site-packages (from mtcnn->keras-facenet) (1.5.1)\n",
      "Collecting lz4>=4.3.3 (from mtcnn->keras-facenet)\n",
      "  Downloading lz4-4.4.4-cp310-cp310-win_amd64.whl.metadata (3.9 kB)\n",
      "Downloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 1.6/1.9 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 8.1 MB/s eta 0:00:00\n",
      "Downloading lz4-4.4.4-cp310-cp310-win_amd64.whl (99 kB)\n",
      "Building wheels for collected packages: keras-facenet\n",
      "  Building wheel for keras-facenet (setup.py): started\n",
      "  Building wheel for keras-facenet (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-facenet: filename=keras_facenet-0.3.2-py3-none-any.whl size=10388 sha256=979fdd89f6da8e77c42db0449d82b6604d73941cdb3419fc1aec80b13d7edaa1\n",
      "  Stored in directory: C:\\Users\\ramesh\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-c0skqse9\\wheels\\1d\\d8\\a9\\85cf04ea29321d2afcb82c0caaafdca9195385f9d68cbc7185\n",
      "Successfully built keras-facenet\n",
      "Installing collected packages: lz4, mtcnn, keras-facenet\n",
      "\n",
      "   ------------- -------------------------- 1/3 [mtcnn]\n",
      "   ------------- -------------------------- 1/3 [mtcnn]\n",
      "   -------------------------- ------------- 2/3 [keras-facenet]\n",
      "   ---------------------------------------- 3/3 [keras-facenet]\n",
      "\n",
      "Successfully installed keras-facenet-0.3.2 lz4-4.4.4 mtcnn-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'keras-facenet' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'keras-facenet'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall keras-facenet\n",
    "!pip install keras-facenet --no-cache-dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df298298-193e-4932-bc05-4a0121b4ae89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
      "Predicted: Amitabh Bachchan (similarity: 1.000)\n"
     ]
    }
   ],
   "source": [
    "from keras_facenet import FaceNet\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "IMG_SIZE = 160\n",
    "TRAIN_DIR = 'dataset/train'\n",
    "TEST_PATH = 'dataset/test/test.jpg'\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "    img = img_to_array(img)\n",
    "    img = img / 255.0\n",
    "    return np.expand_dims(img, axis=0)\n",
    "\n",
    "# Load pretrained FaceNet\n",
    "embedder = FaceNet()\n",
    "\n",
    "# 1. Get embeddings for training images\n",
    "def get_train_embeddings(train_dir):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "\n",
    "    for person in os.listdir(train_dir):\n",
    "        person_folder = os.path.join(train_dir, person)\n",
    "        if not os.path.isdir(person_folder): continue\n",
    "\n",
    "        for img_name in os.listdir(person_folder):\n",
    "            img_path = os.path.join(person_folder, img_name)\n",
    "            img = preprocess_image(img_path)\n",
    "            emb = embedder.embeddings(img)[0]\n",
    "            embeddings.append(emb)\n",
    "            labels.append(person)\n",
    "\n",
    "    return np.array(embeddings), labels\n",
    "\n",
    "# 2. Get embedding for test image\n",
    "def get_test_embedding(image_path):\n",
    "    img = preprocess_image(image_path)\n",
    "    return embedder.embeddings(img)[0]\n",
    "\n",
    "# 3. Predict\n",
    "def predict_identity(test_embedding, train_embeddings, train_labels):\n",
    "    sims = cosine_similarity([test_embedding], train_embeddings)\n",
    "    best_idx = np.argmax(sims)\n",
    "    return train_labels[best_idx], sims[0][best_idx]\n",
    "\n",
    "# Run\n",
    "train_embeddings, train_labels = get_train_embeddings(TRAIN_DIR)\n",
    "test_embedding = get_test_embedding(TEST_PATH)\n",
    "pred_name, score = predict_identity(test_embedding, train_embeddings, train_labels)\n",
    "\n",
    "print(f\"Predicted: {pred_name} (similarity: {score:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab49c633-2d53-4491-9afa-c6f06e3e1138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
